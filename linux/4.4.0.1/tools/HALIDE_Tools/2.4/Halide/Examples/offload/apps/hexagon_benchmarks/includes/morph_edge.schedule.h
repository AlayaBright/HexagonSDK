/* ==================================================================================== */
/*     Copyright (c) 2016-2021 QUALCOMM Technologies, Inc. and/or its subsidiaries.     */
/*                           All Rights Reserved.                                       */
/*                  QUALCOMM Confidential and Proprietary                               */
/* ==================================================================================== */

#ifndef morph_edge_SCHEDULE_H
#define morph_edge_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Adams2019
// for target=arm-64-android-hvx-hvx_128  // NOLINT
// with machine_params=16,24000000,40

#include "Halide.h"


inline void apply_schedule_morph_edge(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target
) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;
    Func output = pipeline.get_func(9);
    Func fin = pipeline.get_func(8);
    Func mx = pipeline.get_func(7);
    Func max_y = pipeline.get_func(6);
    Func mn = pipeline.get_func(5);
    Func min_y = pipeline.get_func(4);
    Func bounded_input = pipeline.get_func(3);
    Func repeat_edge = pipeline.get_func(2);
    Func lambda_0 = pipeline.get_func(1);
    Func input_im = pipeline.get_func(0);
    Var x(output.get_schedule().dims()[0].var);
    Var xi("xi");
    Var xii("xii");
    Var xiii("xiii");
    Var y(output.get_schedule().dims()[1].var);
    Var yi("yi");
    Var yii("yii");
    Var yiii("yiii");
    output
        .split(y, y, yi, 135, TailStrategy::ShiftInwards)
        .split(x, x, xi, 1920, TailStrategy::ShiftInwards)
        .split(yi, yi, yii, 68, TailStrategy::ShiftInwards)
        .split(yii, yii, yiii, 4, TailStrategy::ShiftInwards)
        .split(xi, xi, xii, 384, TailStrategy::ShiftInwards)
        .split(xii, xii, xiii, 128, TailStrategy::ShiftInwards)
        .unroll(xii)
        .unroll(yiii)
        .vectorize(xiii)
        .align_storage(x, 128)
        .compute_root()
        .hexagon()
        .reorder({xiii, xii, yiii, xi, yii, x, yi, y})
        .parallel(y)
        .prefetch(input_im, yii, 2);
    fin
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 128, TailStrategy::RoundUp)
        .unroll(x)
        .unroll(y)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(output, xi)
        .reorder({xi, x, y});
    mx
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 128, TailStrategy::RoundUp)
        .unroll(x)
        .unroll(y)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(output, xi)
        .reorder({xi, x, y});
    max_y
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 128, TailStrategy::RoundUp)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(output, yii)
        .reorder({xi, x, y});
    mn
        .store_in(MemoryType::Stack)
        .split(y, y, yi, 2, TailStrategy::RoundUp)
        .split(x, x, xi, 128, TailStrategy::RoundUp)
        .unroll(x)
        .unroll(yi)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(output, xi)
        .reorder({xi, x, yi, y});
    min_y
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 128, TailStrategy::RoundUp)
        .unroll(x)
        .unroll(y)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(mn, y)
        .reorder({xi, x, y});
    bounded_input
        .store_in(MemoryType::Stack)
        .split(x, x, xi, 128, TailStrategy::ShiftInwards)
        .vectorize(xi)
        .align_storage(x, 128)
        .compute_at(output, yii)
        .store_at(output, x)
        .reorder({xi, x, y});

}

#endif  // morph_edge_SCHEDULE_H
